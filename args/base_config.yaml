# Base Configuration Template for Multimodal CoCoNuT
# This serves as the foundation for all other configuration files

# Experiment settings
seed: 42
project: "multimodal-coconut"
debug: false

# Model configuration
model_id: "OpenGVLab/InternVL3-1B-Pretrained"
load_model_path: "None"

# CoCoNuT parameters (can be overridden)
c_thought: 2
max_latent_stage: 4
epochs_per_stage: 5
uniform_prob: 0.1
pad_latent_to_max: false
no_cot: false

# Training parameters
learning_rate: 1e-5
weight_decay: 0.01
warmup_steps: 1000
gradient_clip_norm: 1.0
gradient_accumulation_steps: 1
max_grad_norm: 1.0

# Multimodal parameters
image_size: 448
max_num_patches: 12
use_thumbnail: true
dynamic_preprocess: true

# Data paths (should be overridden in specific configs)
train_data_path: "data/aokvqa/train.json"
val_data_path: "data/aokvqa/val.json"
test_data_path: "data/aokvqa/test.json"
image_root: "data/aokvqa/images"

# Data limits (for debugging/testing)
max_train_samples: 1000000000  # No limit by default
max_val_samples: 1000000000    # No limit by default

# Distributed training
use_fsdp: true
use_ddp: false
num_workers: 4

# Evaluation
eval_every_n_epochs: 5

# Checkpointing
save_path: "checkpoints"
resume: 0
save_every_n_epochs: 5
save_only_improve: false

# Logging
log_level: "INFO"
use_wandb: true
wandb_project: "multimodal-coconut"

# Additional parameters
reset_optimizer: false
bf16: false